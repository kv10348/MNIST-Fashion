{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.94035223214286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"top\",\"trouser\",\"pullover\",\"dress\",\"coat\",\"sandal\",\"shirt\",\"sneaker\",\"bag\",\"ankle boat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATA Expration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f7e13306a50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_train[2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= x_train/255.0\n",
    "x_test= x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f7e1306a990>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_train[1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build the model with tf2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model compilation\n",
    "    - loss function\n",
    "    - optimizer\n",
    "    - metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "6000/6000 [==============================] - 106s 18ms/step - loss: 0.4803 - accuracy: 0.8291\n",
      "Epoch 2/15\n",
      "6000/6000 [==============================] - 115s 19ms/step - loss: 0.3678 - accuracy: 0.8669\n",
      "Epoch 3/15\n",
      "6000/6000 [==============================] - 126s 21ms/step - loss: 0.3330 - accuracy: 0.8780\n",
      "Epoch 4/15\n",
      "6000/6000 [==============================] - 116s 19ms/step - loss: 0.3118 - accuracy: 0.8852\n",
      "Epoch 5/15\n",
      "6000/6000 [==============================] - 124s 21ms/step - loss: 0.2956 - accuracy: 0.8913\n",
      "Epoch 6/15\n",
      "6000/6000 [==============================] - 128s 21ms/step - loss: 0.2807 - accuracy: 0.8962\n",
      "Epoch 7/15\n",
      "6000/6000 [==============================] - 131s 22ms/step - loss: 0.2712 - accuracy: 0.8995\n",
      "Epoch 8/15\n",
      "6000/6000 [==============================] - 128s 21ms/step - loss: 0.2630 - accuracy: 0.9013\n",
      "Epoch 9/15\n",
      "6000/6000 [==============================] - 131s 22ms/step - loss: 0.2529 - accuracy: 0.9056\n",
      "Epoch 10/15\n",
      "6000/6000 [==============================] - 135s 22ms/step - loss: 0.2452 - accuracy: 0.9090\n",
      "Epoch 11/15\n",
      "6000/6000 [==============================] - 147s 25ms/step - loss: 0.2382 - accuracy: 0.9111\n",
      "Epoch 12/15\n",
      "6000/6000 [==============================] - 144s 24ms/step - loss: 0.2300 - accuracy: 0.9147\n",
      "Epoch 13/15\n",
      "6000/6000 [==============================] - 109s 18ms/step - loss: 0.2256 - accuracy: 0.9167\n",
      "Epoch 14/15\n",
      "6000/6000 [==============================] - 88s 15ms/step - loss: 0.2190 - accuracy: 0.9179\n",
      "Epoch 15/15\n",
      "6000/6000 [==============================] - 83s 14ms/step - loss: 0.2128 - accuracy: 0.9193\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3866 - accuracy: 0.8808\n",
      "0.8808000087738037\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_acc= model.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =np.argmax(model.predict(x_test),axis=-1)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8808"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module tensorflow.python.keras.engine.sequential object:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.training.Model)\n",
      " |  Sequential(*args, **kwargs)\n",
      " |  \n",
      " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
      " |  \n",
      " |  `Sequential` provides training and inference features on this model.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> # Afterwards, we do automatic shape inference:\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  \n",
      " |  >>> # This is identical to the following:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_dim=16))\n",
      " |  \n",
      " |  >>> # And to the following:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, batch_input_shape=(None, 16)))\n",
      " |  \n",
      " |  >>> # Note that you can also omit the `input_shape` argument.\n",
      " |  >>> # In that case the model doesn't have any weights until the first call\n",
      " |  >>> # to a training/evaluation method (since it isn't yet built):\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> # model.weights not created yet\n",
      " |  \n",
      " |  >>> # Whereas if you specify the input shape, the model gets built\n",
      " |  >>> # continuously as you are adding layers:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  >>> # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  >>> # choose to manually build your model by calling\n",
      " |  >>> # `build(batch_input_shape)`:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> model.build((None, 16))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  ```python\n",
      " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
      " |  # the model gets built the first time you call `fit` (or other training and\n",
      " |  # evaluation methods).\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(1))\n",
      " |  model.compile(optimizer='sgd', loss='mse')\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.network.Network\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Creates a `Sequential` model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        layers: Optional list of layers to add to the model.\n",
      " |        name: Optional name for the model.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2021-01-01.\n",
      " |      Instructions for updating:\n",
      " |      Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2021-01-01.\n",
      " |      Instructions for updating:\n",
      " |      Please use `model.predict()` instead.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the network's input specs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |              `tf.keras.losses.Loss` instance. See `tf.keras.losses`.\n",
      " |              An objective function is any callable with the signature\n",
      " |              `loss = fn(y_true, y_pred)`, where\n",
      " |              y_true = ground truth values with shape = `[batch_size, d0, .. dN]`,\n",
      " |              except sparse loss functions such as sparse categorical crossentropy\n",
      " |              where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |              y_pred = predicted values with shape = `[batch_size, d0, .. dN]`.\n",
      " |              It returns a weighted loss float tensor.\n",
      " |              If a custom `Loss` instance is used and reduction is set to NONE,\n",
      " |              return value has the shape [batch_size, d0, .. dN-1] ie. per-sample\n",
      " |              or per-timestep loss values; otherwise, it is a scalar.\n",
      " |              If the model has multiple outputs, you can use a different loss on\n",
      " |              each output by passing a dictionary or a list of losses. The loss\n",
      " |              value that will be minimized by the model will then be the sum of\n",
      " |              all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |              and testing.\n",
      " |              Each of this can be a string (name of a built-in function), function\n",
      " |              or a `tf.keras.metrics.Metric` instance. See `tf.keras.metrics`.\n",
      " |              Typically you will use `metrics=['accuracy']`. A function is any\n",
      " |              callable with the signature `result = fn(y_true, y_pred)`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      " |              When you pass the strings 'accuracy' or 'acc', we convert this to\n",
      " |              one of `tf.keras.metrics.BinaryAccuracy`,\n",
      " |              `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |              `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |              function used and the model output shape. We do a similar conversion\n",
      " |              for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a dict, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          **kwargs: Any additional arguments. For eager execution, pass\n",
      " |              `run_eagerly=True`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs. - A `tf.data` dataset. - A generator or\n",
      " |            `keras.utils.Sequence` instance. A more detailed description of\n",
      " |            unpacking behavior for iterator types (Dataset, generator, Sequence)\n",
      " |            is given in the `Unpacking behavior for iterator-like inputs` section\n",
      " |            of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per gradient update. If\n",
      " |            unspecified, `batch_size` will default to 32. Do not specify the\n",
      " |            `batch_size` if your data is in the form of a dataset, generators,\n",
      " |            or `keras.utils.Sequence` instances (since they generate batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. In this case you should make sure to specify\n",
      " |                `sample_weight_mode=\"temporal\"` in `compile()`. This argument is\n",
      " |                not supported when `x` is a dataset, instead pass sample weights\n",
      " |                as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
      " |            execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.evaluate, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |              Note that `validation_data` does not support all the data types that\n",
      " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator. 'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.fit, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.predict, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathemetical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of metrics.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample. In this case you should make sure to specify\n",
      " |            sample_weight_mode=\"temporal\" in compile().\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathemetical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample. In this case you should make sure to specify\n",
      " |            sample_weight_mode=\"temporal\" in compile().\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathemetical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: `metrics` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> _ = model.fit(x, (y, y), verbose=0)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> _ = model.fit(x, (y, y), verbose=0)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model` is a compiled model ready to be used\n",
      " |      (unless the saved model was never compiled in the first place).\n",
      " |      \n",
      " |      Models built with the Sequential and Functional API can be saved to both the\n",
      " |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
      " |      SavedModel format.\n",
      " |      \n",
      " |      Note that the model weights may have different scoped names after being\n",
      " |      loaded. Scoped names include the model/layer names, such as\n",
      " |      \"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n",
      " |       access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      " |              to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X, and\n",
      " |              'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
      " |              options for saving to SavedModel.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the file to save the weights to. When saving\n",
      " |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      " |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      " |              weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |      Dtype used by the weights of the layer, set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.48027974367141724,\n",
       "  0.3677527606487274,\n",
       "  0.3330349922180176,\n",
       "  0.31175872683525085,\n",
       "  0.29560545086860657,\n",
       "  0.28074365854263306,\n",
       "  0.2711651921272278,\n",
       "  0.2630324065685272,\n",
       "  0.25288429856300354,\n",
       "  0.24517561495304108,\n",
       "  0.2381817102432251,\n",
       "  0.22999753057956696,\n",
       "  0.22557929158210754,\n",
       "  0.219017893075943,\n",
       "  0.21275831758975983],\n",
       " 'accuracy': [0.8291333317756653,\n",
       "  0.8668500185012817,\n",
       "  0.878000020980835,\n",
       "  0.8852499723434448,\n",
       "  0.8913000226020813,\n",
       "  0.8962000012397766,\n",
       "  0.8994666934013367,\n",
       "  0.9013166427612305,\n",
       "  0.9055833220481873,\n",
       "  0.9090499877929688,\n",
       "  0.911050021648407,\n",
       "  0.9146999716758728,\n",
       "  0.916700005531311,\n",
       "  0.9179166555404663,\n",
       "  0.9192500114440918]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
